<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Blog Of PuppetSama"><title>目标爬虫清单 | PuppetHut</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">目标爬虫清单</h1><a id="logo" href="/.">PuppetHut</a><p class="description">Someday I'll be just like you.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">目标爬虫清单</h1><div class="post-meta">Oct 26, 2017<span> | </span><span class="category"><a href="/categories/Code/">Code</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#网易云音乐的音乐"><span class="toc-number">1.</span> <span class="toc-text">网易云音乐的音乐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#花瓣采集的图片"><span class="toc-number">2.</span> <span class="toc-text">花瓣采集的图片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#instagram的图片"><span class="toc-number">3.</span> <span class="toc-text">instagram的图片</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#直接爬取"><span class="toc-number">3.1.</span> <span class="toc-text">直接爬取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#维基百科编辑ip分布地图"><span class="toc-number">4.</span> <span class="toc-text">维基百科编辑ip分布地图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#微博情绪地图"><span class="toc-number">5.</span> <span class="toc-text">微博情绪地图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#拉勾网实习搜索"><span class="toc-number">6.</span> <span class="toc-text">拉勾网实习搜索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#matplotlib示例代码下载"><span class="toc-number">7.</span> <span class="toc-text">matplotlib示例代码下载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#项目说明"><span class="toc-number">7.1.</span> <span class="toc-text">项目说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#页面分析"><span class="toc-number">7.2.</span> <span class="toc-text">页面分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编码实现"><span class="toc-number">7.3.</span> <span class="toc-text">编码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#杭电图书馆图书"><span class="toc-number">8.</span> <span class="toc-text">杭电图书馆图书</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#豆瓣阅读热门标签"><span class="toc-number">9.</span> <span class="toc-text">豆瓣阅读热门标签</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#项目说明-1"><span class="toc-number">9.1.</span> <span class="toc-text">项目说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#值得学习"><span class="toc-number">9.2.</span> <span class="toc-text">值得学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#utf8格式存储json"><span class="toc-number">9.2.1.</span> <span class="toc-text">utf8格式存储json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#随机选择代理"><span class="toc-number">9.2.2.</span> <span class="toc-text">随机选择代理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#不足之处"><span class="toc-number">9.3.</span> <span class="toc-text">不足之处</span></a></li></ol></li></ol></div></div><div class="post-content"><p>想了想决定，把想要爬的网站都汇总起来，一方面是这样更方便清晰，另一方面也是督促自己每天都编程。</p>
<p>完成后会顺带写上关键点和一些心得。</p>
<p><em>先定个小目标，爬他100个</em><br><a id="more"></a></p>
<h2 id="网易云音乐的音乐"><a href="#网易云音乐的音乐" class="headerlink" title="网易云音乐的音乐"></a>网易云音乐的音乐</h2><h2 id="花瓣采集的图片"><a href="#花瓣采集的图片" class="headerlink" title="花瓣采集的图片"></a>花瓣采集的图片</h2><h2 id="instagram的图片"><a href="#instagram的图片" class="headerlink" title="instagram的图片"></a>instagram的图片</h2><h3 id="直接爬取"><a href="#直接爬取" class="headerlink" title="直接爬取"></a>直接爬取</h3><p>最简单的爬取方式大概就是直接爬取了，单纯使用request方法就可以拿到目标信息，不需要添加头文件也不需要进行模拟登录，甚至动态加载的部分都可以通过instagram的更多的herf进行跳转从而避开抓包步骤。但是考虑到效率问题，只适用于较少链接的爬取，发帖数应当少于200。</p>
<p><a href="https://github.com/PuppetSama/InstagramSpider/blob/master/directIns.py" target="_blank" rel="external">示例代码</a></p>
<h2 id="维基百科编辑ip分布地图"><a href="#维基百科编辑ip分布地图" class="headerlink" title="维基百科编辑ip分布地图"></a>维基百科编辑ip分布地图</h2><h2 id="微博情绪地图"><a href="#微博情绪地图" class="headerlink" title="微博情绪地图"></a>微博情绪地图</h2><h2 id="拉勾网实习搜索"><a href="#拉勾网实习搜索" class="headerlink" title="拉勾网实习搜索"></a>拉勾网实习搜索</h2><h2 id="matplotlib示例代码下载"><a href="#matplotlib示例代码下载" class="headerlink" title="matplotlib示例代码下载"></a>matplotlib示例代码下载</h2><h3 id="项目说明"><a href="#项目说明" class="headerlink" title="项目说明"></a>项目说明</h3><p>采用scrapy框架可以快速下载，使用FilesPipeline(可以看作是特殊的下载器，通过item的一个特殊字段将目标文件的url传递给它，就可以自动下载，并将下载结果信息存入item的另一个字段，方便查阅)。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>FilesPipeline</strong></th>
<th><strong>ImagesPipeline</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>导入路径</td>
<td>scrapy.pipelines.files.FilesPipeline</td>
<td>secrapy.pipeline.images.ImagesPipeline</td>
</tr>
<tr>
<td>Item字段</td>
<td>file_urls,files</td>
<td>image_urls,images</td>
</tr>
<tr>
<td>下载目录</td>
<td>FILE_STORE</td>
<td>IMAGES_STORE</td>
</tr>
</tbody>
</table>
</div>
<h3 id="页面分析"><a href="#页面分析" class="headerlink" title="页面分析"></a>页面分析</h3><ul>
<li>使用scrapy shell来下载目标界面,然后调用view函数在浏览器查看。</li>
<li>发现例子页面链接，使用LinkExtractor提取所有例子页面链接。</li>
<li>分析例子页面，使用fetch函数进入下载第一个例子页面，调用view函数查看。</li>
<li>分析下载地址，完成。</li>
</ul>
<h3 id="编码实现"><a href="#编码实现" class="headerlink" title="编码实现"></a>编码实现</h3><ul>
<li>创建Scrapy项目。</li>
<li>在配置文件启用FilesPipeline，指定下载目录。</li>
<li>实现Item。</li>
<li>实现Spider。</li>
</ul>
<p>下载完成后，发现文件名为一串数字，这些数字是下载文件url的sha1散列值。这种命名方式可以防止重名文件相互覆盖，但并不直观。</p>
<p>实现一个FilesPipeline的子类，覆写file_path方法来实现期望的文件命名规则。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="title">from</span> scrapy.pipelines.files <span class="keyword">import</span> FilesPipeline</div><div class="line"><span class="title">from</span> urllib.parse <span class="keyword">import</span> urlparse</div><div class="line"><span class="title">from</span> os.path <span class="keyword">import</span> basename, dirname, join</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="type">MatpoltlibexamplePipeline</span>(<span class="type">FilesPipeline</span>):</span></div><div class="line"><span class="class">    def file_path(<span class="title">self</span>, <span class="title">request</span>, <span class="title">response</span>=<span class="type">None</span>, <span class="title">info</span>=<span class="type">None</span>):</span></div><div class="line"><span class="class">    	path=urlparse(<span class="title">request</span>.<span class="title">url</span>).path</span></div><div class="line"><span class="class">    	return join(<span class="title">basename</span>(<span class="title">dirname</span>(<span class="title">path</span>)), basename(<span class="title">path</span>))</span></div></pre></td></tr></table></figure>
<h2 id="杭电图书馆图书"><a href="#杭电图书馆图书" class="headerlink" title="杭电图书馆图书"></a>杭电图书馆图书</h2><h2 id="豆瓣阅读热门标签"><a href="#豆瓣阅读热门标签" class="headerlink" title="豆瓣阅读热门标签"></a>豆瓣阅读热门标签</h2><h3 id="项目说明-1"><a href="#项目说明-1" class="headerlink" title="项目说明"></a>项目说明</h3><p>爬取<a href="https://book.douban.com/tag/?view=cloud" target="_blank" rel="external">豆瓣阅读所有热门标签</a>下的书籍名称，评分和评价人数。</p>
<p>这个项目的起因是有朋友需要对豆瓣阅读的信息进行数据挖掘，刚好自己没什么事情就随手写了，具体实现并不困难。</p>
<h3 id="值得学习"><a href="#值得学习" class="headerlink" title="值得学习"></a>值得学习</h3><h4 id="utf8格式存储json"><a href="#utf8格式存储json" class="headerlink" title="utf8格式存储json"></a>utf8格式存储json</h4><p>代码如下：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubannovelPipeline</span>(<span class="title">object</span>):</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></div><div class="line">		<span class="keyword">self</span>.file = codecs.open(<span class="string">'douban_novel_utf8.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(<span class="keyword">self</span>, item, spider)</span></span><span class="symbol">:</span></div><div class="line">		line = json.dumps(dict(item), ensure_ascii=False) + <span class="string">"\n"</span></div><div class="line">		<span class="keyword">self</span>.file.write(line)</div><div class="line">		<span class="keyword">return</span> item</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">spider_closed</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></div><div class="line">		<span class="keyword">self</span>.file.close()</div></pre></td></tr></table></figure></p>
<h4 id="随机选择代理"><a href="#随机选择代理" class="headerlink" title="随机选择代理"></a>随机选择代理</h4><p>代码如下：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubannovelSpiderMiddleware</span>(<span class="title">HttpProxyMiddleware</span>):</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, auth_encoding=<span class="string">'latin-1'</span>, proxy_list_file=None)</span></span><span class="symbol">:</span></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">proxy_list_file:</span></div><div class="line">            raise NotConfigured</div><div class="line">        <span class="keyword">self</span>.auth_encoding = auth_encoding</div><div class="line">        <span class="comment"># 分别用两个列表维护HTTP和HTTPS的代理</span></div><div class="line">        <span class="keyword">self</span>.proxies = defaultdict(list)</div><div class="line"></div><div class="line">        <span class="comment"># 从json文件中读取代理服务器信息，填入self.proxies</span></div><div class="line">        with open(proxy_list_file) as <span class="symbol">f:</span></div><div class="line">            proxy_list = json.load(f)</div><div class="line">            <span class="keyword">for</span> proxy <span class="keyword">in</span> <span class="symbol">proxy_list:</span></div><div class="line">                scheme = proxy[<span class="string">'proxy_scheme'</span>]</div><div class="line">                url = proxy[<span class="string">'proxy'</span>]</div><div class="line">                <span class="keyword">self</span>.proxies[scheme].append(<span class="keyword">self</span>._get_proxy(url,scheme))</div><div class="line"></div><div class="line"></div><div class="line">    @classmethod</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span></span><span class="symbol">:</span></div><div class="line">        <span class="comment"># 从配置文件中读取用户验证信息编码</span></div><div class="line">        auth_encoding = crawler.settings.get(<span class="string">'HTTPPROXY_AUTH_ENCODING'</span>, <span class="string">'latin-1'</span>)</div><div class="line">        <span class="comment"># 从配置文件中读取代理服务器列表文件(json)的路径</span></div><div class="line">        proxy_list_file = crawler.settings.get(<span class="string">'HTTPPROXY_PROXY_LIST_FILE'</span>)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> cls(auth_encoding, proxy_list_file)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_opened</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></div><div class="line">        spider.logger.info(<span class="string">'Spider opened: %s'</span> % spider.name)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_set_proxy</span><span class="params">(<span class="keyword">self</span>, request, scheme)</span></span><span class="symbol">:</span></div><div class="line">        <span class="comment"># 随机选择一个代理</span></div><div class="line">        creds, proxy = random.choice(<span class="keyword">self</span>.proxies[scheme])</div><div class="line">        request.meta[<span class="string">'proxy'</span>] = proxy</div><div class="line">        <span class="keyword">if</span> <span class="symbol">creds:</span></div><div class="line">            request.headers[<span class="string">'Proxy-Authorization'</span>] = b<span class="string">'Basic'</span> + creds</div></pre></td></tr></table></figure></p>
<h3 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h3><ul>
<li>数据量非常大，大概有10w多条，由于使用没有进行分布式处理也没有挂在服务器上跑，导致电脑被占用了一个下午，心痛。</li>
<li>随机代理无法自动删除无效代理，无法重新下载失败链接，导致失败链接丢失，影响下载质量。</li>
<li>豆瓣页面明明写的20本书！但是部分页面实际只有19本！骗子！过分！！哼！！！</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://puppetkant.cn/2017/10/26/目标爬虫清单/" data-id="cjg9iqmzy0019soud04uaao4x" class="article-share-link">分享</a><div class="tags"><a href="/tags/Python/">Python</a></div><div class="post-nav"><a href="/2017/12/05/《think-python》读书笔记/" class="pre">《think_python》读书笔记</a><a href="/2017/10/20/Python动态爬取的两种方式/" class="next">Python动态爬取的两种方式</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://puppetkant.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code/">Code</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Game/">Game</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Read/">Read</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/mc/" style="font-size: 15px;">mc</a> <a href="/tags/Others/" style="font-size: 15px;">Others</a> <a href="/tags/Algorithm/" style="font-size: 15px;">Algorithm</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/21/浅析k近邻算法/">浅析k近邻算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/01/假装很开心/">假装很开心</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/05/《think-python》读书笔记/">《think_python》读书笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/26/目标爬虫清单/">目标爬虫清单</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/20/Python动态爬取的两种方式/">Python动态爬取的两种方式</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/19/数字杭电模拟登录/">数字杭电模拟登录</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/07/Python爬坑问题集合/">Python爬坑问题集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/01/国内携程一日航线Python实现/">国内携程一日航线Python实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/28/思考的独立性/">思考的独立性</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/09/Python-爬虫笔记（三）——对于Lambda的认识/">Python 爬虫笔记（三）——对于Lambda的认识</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://mikumiku.com.cn/" title="Xana's blog" target="_blank">Xana's blog</a><ul></ul><a href="http://fogdong.github.io/" title="FogDong's blog" target="_blank">FogDong's blog</a><ul></ul><a href="http://yorhp.com/" title="Tyhj's blog" target="_blank">Tyhj's blog</a><ul></ul><a href="https://tecotaku.cn/" title="Sino's blog" target="_blank">Sino's blog</a><ul></ul><a href="http://hellovass.info/" title="HelloVass's blog" target="_blank">HelloVass's blog</a><ul></ul><a href="http://qingmicity.cn/" title="QingMi's blog" target="_blank">QingMi's blog</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">PuppetHut.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>